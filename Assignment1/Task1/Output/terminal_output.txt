himanshu@himanshu:~/BigData/hadoop-3.2.1$ bin/hadoop jar '/home/himanshu/BigData/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar' -mapper "python /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/mapper_task1.py airplane" -reducer 'python /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/reducer_task1.py' -input /Input/ -output /Output/task1_airplane
2020-09-02 19:47:39,287 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-09-02 19:47:39,349 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-09-02 19:47:39,349 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2020-09-02 19:47:39,365 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2020-09-02 19:47:40,025 INFO mapred.FileInputFormat: Total input files to process : 1
2020-09-02 19:47:40,031 INFO net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:9866
2020-09-02 19:47:40,043 INFO mapreduce.JobSubmitter: number of splits:1
2020-09-02 19:47:40,308 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1738646166_0001
2020-09-02 19:47:40,308 INFO mapreduce.JobSubmitter: Executing with tokens: []
2020-09-02 19:47:40,500 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2020-09-02 19:47:40,506 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2020-09-02 19:47:40,507 INFO mapreduce.Job: Running job: job_local1738646166_0001
2020-09-02 19:47:40,508 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2020-09-02 19:47:40,530 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:47:40,531 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:47:40,630 INFO mapred.LocalJobRunner: Waiting for map tasks
2020-09-02 19:47:40,633 INFO mapred.LocalJobRunner: Starting task: attempt_local1738646166_0001_m_000000_0
2020-09-02 19:47:40,673 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:47:40,673 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:47:40,725 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2020-09-02 19:47:40,748 INFO mapred.MapTask: Processing split: hdfs://localhost:8020/Input/plane_carriers.ndjson:0+146792696
2020-09-02 19:47:40,771 INFO mapred.MapTask: numReduceTasks: 1
2020-09-02 19:47:41,415 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2020-09-02 19:47:41,415 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2020-09-02 19:47:41,415 INFO mapred.MapTask: soft limit at 83886080
2020-09-02 19:47:41,415 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2020-09-02 19:47:41,415 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2020-09-02 19:47:41,418 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-09-02 19:47:41,529 INFO mapreduce.Job: Job job_local1738646166_0001 running in uber mode : false
2020-09-02 19:47:41,532 INFO mapreduce.Job:  map 0% reduce 0%
2020-09-02 19:47:41,578 INFO streaming.PipeMapRed: PipeMapRed exec [/home/himanshu/anaconda3/bin/python, /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/mapper_task1.py, airplane]
2020-09-02 19:47:41,594 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2020-09-02 19:47:41,596 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
2020-09-02 19:47:41,597 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2020-09-02 19:47:41,598 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2020-09-02 19:47:41,600 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2020-09-02 19:47:41,600 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2020-09-02 19:47:41,600 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2020-09-02 19:47:41,604 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-09-02 19:47:41,605 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
2020-09-02 19:47:41,606 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2020-09-02 19:47:41,606 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2020-09-02 19:47:41,607 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2020-09-02 19:47:41,643 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-09-02 19:47:41,722 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:41,723 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:41,729 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:42,138 INFO streaming.PipeMapRed: R/W/S=1000/1/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:42,139 INFO streaming.PipeMapRed: Records R/W=1000/1
2020-09-02 19:47:42,401 INFO streaming.PipeMapRed: R/W/S=10000/8211/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:44,998 INFO streaming.PipeMapRed: R/W/S=100000/91098/0 in:33333=100000/3 [rec/s] out:30366=91098/3 [rec/s]
2020-09-02 19:47:48,151 INFO streaming.PipeMapRed: R/W/S=200000/138889/0 in:33333=200000/6 [rec/s] out:23148=138889/6 [rec/s]
2020-09-02 19:47:50,162 INFO streaming.PipeMapRed: MRErrorThread done
2020-09-02 19:47:50,162 INFO streaming.PipeMapRed: mapRedFinished
2020-09-02 19:47:50,241 INFO mapred.LocalJobRunner: 
2020-09-02 19:47:50,242 INFO mapred.MapTask: Starting flush of map output
2020-09-02 19:47:50,242 INFO mapred.MapTask: Spilling map output
2020-09-02 19:47:50,242 INFO mapred.MapTask: bufstart = 0; bufend = 1525034; bufvoid = 104857600
2020-09-02 19:47:50,242 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25658716(102634864); length = 555681/6553600
2020-09-02 19:47:50,663 INFO mapred.MapTask: Finished spill 0
2020-09-02 19:47:50,870 INFO mapred.Task: Task:attempt_local1738646166_0001_m_000000_0 is done. And is in the process of committing
2020-09-02 19:47:50,966 INFO mapred.LocalJobRunner: Records R/W=1000/1
2020-09-02 19:47:50,967 INFO mapred.Task: Task 'attempt_local1738646166_0001_m_000000_0' done.
2020-09-02 19:47:51,469 INFO mapred.Task: Final Counters for attempt_local1738646166_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=176755
		FILE: Number of bytes written=2511415
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=146792696
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=268127
		Map output records=138921
		Map output bytes=1525034
		Map output materialized bytes=1802882
		Input split bytes=101
		Combine input records=0
		Spilled Records=138921
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=277348352
	File Input Format Counters 
		Bytes Read=146792696
2020-09-02 19:47:51,470 INFO mapred.LocalJobRunner: Finishing task: attempt_local1738646166_0001_m_000000_0
2020-09-02 19:47:51,472 INFO mapred.LocalJobRunner: map task executor complete.
2020-09-02 19:47:51,488 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2020-09-02 19:47:51,488 INFO mapred.LocalJobRunner: Starting task: attempt_local1738646166_0001_r_000000_0
2020-09-02 19:47:51,539 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:47:51,539 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:47:51,541 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2020-09-02 19:47:51,544 INFO mapreduce.Job:  map 100% reduce 0%
2020-09-02 19:47:51,625 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6fe1821f
2020-09-02 19:47:51,630 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2020-09-02 19:47:51,990 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=629040704, maxSingleShuffleLimit=157260176, mergeThreshold=415166880, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-09-02 19:47:51,996 INFO reduce.EventFetcher: attempt_local1738646166_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-09-02 19:47:52,492 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1738646166_0001_m_000000_0 decomp: 1802878 len: 1802882 to MEMORY
2020-09-02 19:47:52,647 INFO reduce.InMemoryMapOutput: Read 1802878 bytes from map-output for attempt_local1738646166_0001_m_000000_0
2020-09-02 19:47:52,677 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1802878, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1802878
2020-09-02 19:47:52,701 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2020-09-02 19:47:52,702 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:47:52,703 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-09-02 19:47:52,783 INFO mapred.Merger: Merging 1 sorted segments
2020-09-02 19:47:52,783 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1802868 bytes
2020-09-02 19:47:52,878 INFO reduce.MergeManagerImpl: Merged 1 segments, 1802878 bytes to disk to satisfy reduce memory limit
2020-09-02 19:47:52,879 INFO reduce.MergeManagerImpl: Merging 1 files, 1802882 bytes from disk
2020-09-02 19:47:52,879 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2020-09-02 19:47:52,880 INFO mapred.Merger: Merging 1 sorted segments
2020-09-02 19:47:52,880 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1802868 bytes
2020-09-02 19:47:52,881 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:47:52,980 INFO streaming.PipeMapRed: PipeMapRed exec [/home/himanshu/anaconda3/bin/python, /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/reducer_task1.py]
2020-09-02 19:47:52,985 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2020-09-02 19:47:52,986 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2020-09-02 19:47:53,339 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:53,340 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:53,344 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:53,361 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:53,391 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:53,564 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:47:53,629 INFO streaming.PipeMapRed: Records R/W=138921/1
2020-09-02 19:47:53,632 INFO streaming.PipeMapRed: MRErrorThread done
2020-09-02 19:47:53,632 INFO streaming.PipeMapRed: mapRedFinished
2020-09-02 19:47:53,793 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-09-02 19:47:53,932 INFO mapred.Task: Task:attempt_local1738646166_0001_r_000000_0 is done. And is in the process of committing
2020-09-02 19:47:53,934 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:47:53,934 INFO mapred.Task: Task attempt_local1738646166_0001_r_000000_0 is allowed to commit now
2020-09-02 19:47:53,979 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1738646166_0001_r_000000_0' to hdfs://localhost:8020/Output/task1_airplane
2020-09-02 19:47:53,980 INFO mapred.LocalJobRunner: Records R/W=138921/1 > reduce
2020-09-02 19:47:53,980 INFO mapred.Task: Task 'attempt_local1738646166_0001_r_000000_0' done.
2020-09-02 19:47:53,981 INFO mapred.Task: Final Counters for attempt_local1738646166_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=3782551
		FILE: Number of bytes written=4314297
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=146792696
		HDFS: Number of bytes written=14
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=1802882
		Reduce input records=138921
		Reduce output records=2
		Spilled Records=138921
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277348352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=14
2020-09-02 19:47:53,982 INFO mapred.LocalJobRunner: Finishing task: attempt_local1738646166_0001_r_000000_0
2020-09-02 19:47:53,982 INFO mapred.LocalJobRunner: reduce task executor complete.
2020-09-02 19:47:54,546 INFO mapreduce.Job:  map 100% reduce 100%
2020-09-02 19:47:54,547 INFO mapreduce.Job: Job job_local1738646166_0001 completed successfully
2020-09-02 19:47:54,562 INFO mapreduce.Job: Counters: 36
	File System Counters
		FILE: Number of bytes read=3959306
		FILE: Number of bytes written=6825712
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=293585392
		HDFS: Number of bytes written=14
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=268127
		Map output records=138921
		Map output bytes=1525034
		Map output materialized bytes=1802882
		Input split bytes=101
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=1802882
		Reduce input records=138921
		Reduce output records=2
		Spilled Records=277842
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=554696704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146792696
	File Output Format Counters 
		Bytes Written=14
2020-09-02 19:47:54,563 INFO streaming.StreamJob: Output directory: /Output/task1_airplane



















































himanshu@himanshu:~/BigData/hadoop-3.2.1$ bin/hadoop jar '/home/himanshu/BigData/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar' -mapp "python /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/mapper_task1.py 'aircraft carrier'" -reducer 'python /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/reducer_task1.py' -input /Input/ -output /Output/task1_aircraft
2020-09-02 19:48:56,743 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-09-02 19:48:56,837 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-09-02 19:48:56,837 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2020-09-02 19:48:56,856 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2020-09-02 19:48:57,458 INFO mapred.FileInputFormat: Total input files to process : 1
2020-09-02 19:48:57,476 INFO net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:9866
2020-09-02 19:48:57,522 INFO mapreduce.JobSubmitter: number of splits:1
2020-09-02 19:48:58,092 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1083685260_0001
2020-09-02 19:48:58,092 INFO mapreduce.JobSubmitter: Executing with tokens: []
2020-09-02 19:48:58,290 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2020-09-02 19:48:58,293 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2020-09-02 19:48:58,293 INFO mapreduce.Job: Running job: job_local1083685260_0001
2020-09-02 19:48:58,295 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2020-09-02 19:48:58,302 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:48:58,302 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:48:58,398 INFO mapred.LocalJobRunner: Waiting for map tasks
2020-09-02 19:48:58,402 INFO mapred.LocalJobRunner: Starting task: attempt_local1083685260_0001_m_000000_0
2020-09-02 19:48:58,449 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:48:58,450 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:48:58,494 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2020-09-02 19:48:58,503 INFO mapred.MapTask: Processing split: hdfs://localhost:8020/Input/plane_carriers.ndjson:0+146792696
2020-09-02 19:48:58,560 INFO mapred.MapTask: numReduceTasks: 1
2020-09-02 19:48:58,666 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2020-09-02 19:48:58,666 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2020-09-02 19:48:58,666 INFO mapred.MapTask: soft limit at 83886080
2020-09-02 19:48:58,666 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2020-09-02 19:48:58,666 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2020-09-02 19:48:58,669 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-09-02 19:48:58,676 INFO streaming.PipeMapRed: PipeMapRed exec [/home/himanshu/anaconda3/bin/python, /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/mapper_task1.py, aircraft carrier]
2020-09-02 19:48:58,682 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2020-09-02 19:48:58,683 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
2020-09-02 19:48:58,683 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2020-09-02 19:48:58,684 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2020-09-02 19:48:58,684 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2020-09-02 19:48:58,684 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2020-09-02 19:48:58,684 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2020-09-02 19:48:58,685 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-09-02 19:48:58,685 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
2020-09-02 19:48:58,685 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2020-09-02 19:48:58,685 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2020-09-02 19:48:58,686 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2020-09-02 19:48:58,747 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-09-02 19:48:59,155 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:48:59,156 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:48:59,162 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:48:59,299 INFO mapreduce.Job: Job job_local1083685260_0001 running in uber mode : false
2020-09-02 19:48:59,301 INFO mapreduce.Job:  map 0% reduce 0%
2020-09-02 19:48:59,353 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:48:59,547 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:49:01,819 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:33333=100000/3 [rec/s] out:0=0/3 [rec/s]
2020-09-02 19:49:03,200 INFO streaming.PipeMapRed: Records R/W=152352/1
2020-09-02 19:49:04,616 INFO streaming.PipeMapRed: R/W/S=200000/41022/0 in:40000=200000/5 [rec/s] out:8204=41022/5 [rec/s]
2020-09-02 19:49:06,728 INFO streaming.PipeMapRed: MRErrorThread done
2020-09-02 19:49:06,728 INFO streaming.PipeMapRed: mapRedFinished
2020-09-02 19:49:06,731 INFO mapred.LocalJobRunner: 
2020-09-02 19:49:06,731 INFO mapred.MapTask: Starting flush of map output
2020-09-02 19:49:06,731 INFO mapred.MapTask: Spilling map output
2020-09-02 19:49:06,731 INFO mapred.MapTask: bufstart = 0; bufend = 1842528; bufvoid = 104857600
2020-09-02 19:49:06,731 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25817884(103271536); length = 396513/6553600
2020-09-02 19:49:06,844 INFO mapred.MapTask: Finished spill 0
2020-09-02 19:49:06,854 INFO mapred.Task: Task:attempt_local1083685260_0001_m_000000_0 is done. And is in the process of committing
2020-09-02 19:49:06,885 INFO mapred.LocalJobRunner: Records R/W=152352/1
2020-09-02 19:49:06,885 INFO mapred.Task: Task 'attempt_local1083685260_0001_m_000000_0' done.
2020-09-02 19:49:06,901 INFO mapred.Task: Final Counters for attempt_local1083685260_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=176755
		FILE: Number of bytes written=2749353
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=146792696
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=268127
		Map output records=99129
		Map output bytes=1842528
		Map output materialized bytes=2040792
		Input split bytes=101
		Combine input records=0
		Spilled Records=99129
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=276824064
	File Input Format Counters 
		Bytes Read=146792696
2020-09-02 19:49:06,902 INFO mapred.LocalJobRunner: Finishing task: attempt_local1083685260_0001_m_000000_0
2020-09-02 19:49:06,904 INFO mapred.LocalJobRunner: map task executor complete.
2020-09-02 19:49:06,919 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2020-09-02 19:49:06,920 INFO mapred.LocalJobRunner: Starting task: attempt_local1083685260_0001_r_000000_0
2020-09-02 19:49:06,937 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:49:06,937 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:49:06,939 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2020-09-02 19:49:06,951 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a6e0fab
2020-09-02 19:49:06,956 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2020-09-02 19:49:07,034 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=629040704, maxSingleShuffleLimit=157260176, mergeThreshold=415166880, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-09-02 19:49:07,036 INFO reduce.EventFetcher: attempt_local1083685260_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-09-02 19:49:07,071 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1083685260_0001_m_000000_0 decomp: 2040788 len: 2040792 to MEMORY
2020-09-02 19:49:07,077 INFO reduce.InMemoryMapOutput: Read 2040788 bytes from map-output for attempt_local1083685260_0001_m_000000_0
2020-09-02 19:49:07,101 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2040788, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2040788
2020-09-02 19:49:07,103 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2020-09-02 19:49:07,104 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:49:07,104 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-09-02 19:49:07,128 INFO mapred.Merger: Merging 1 sorted segments
2020-09-02 19:49:07,128 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2040778 bytes
2020-09-02 19:49:07,238 INFO reduce.MergeManagerImpl: Merged 1 segments, 2040788 bytes to disk to satisfy reduce memory limit
2020-09-02 19:49:07,239 INFO reduce.MergeManagerImpl: Merging 1 files, 2040792 bytes from disk
2020-09-02 19:49:07,240 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2020-09-02 19:49:07,240 INFO mapred.Merger: Merging 1 sorted segments
2020-09-02 19:49:07,241 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2040778 bytes
2020-09-02 19:49:07,241 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:49:07,245 INFO streaming.PipeMapRed: PipeMapRed exec [/home/himanshu/anaconda3/bin/python, /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/reducer_task1.py]
2020-09-02 19:49:07,248 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2020-09-02 19:49:07,249 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2020-09-02 19:49:07,310 INFO mapreduce.Job:  map 100% reduce 0%
2020-09-02 19:49:08,037 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:49:08,037 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:49:08,039 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:49:08,048 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:49:08,083 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:49:08,274 INFO streaming.PipeMapRed: Records R/W=99129/1
2020-09-02 19:49:08,277 INFO streaming.PipeMapRed: MRErrorThread done
2020-09-02 19:49:08,277 INFO streaming.PipeMapRed: mapRedFinished
2020-09-02 19:49:09,081 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-09-02 19:49:09,246 INFO mapred.Task: Task:attempt_local1083685260_0001_r_000000_0 is done. And is in the process of committing
2020-09-02 19:49:09,254 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:49:09,255 INFO mapred.Task: Task attempt_local1083685260_0001_r_000000_0 is allowed to commit now
2020-09-02 19:49:09,520 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1083685260_0001_r_000000_0' to hdfs://localhost:8020/Output/task1_aircraft
2020-09-02 19:49:09,522 INFO mapred.LocalJobRunner: Records R/W=99129/1 > reduce
2020-09-02 19:49:09,522 INFO mapred.Task: Task 'attempt_local1083685260_0001_r_000000_0' done.
2020-09-02 19:49:09,523 INFO mapred.Task: Final Counters for attempt_local1083685260_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=4258371
		FILE: Number of bytes written=4790145
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=146792696
		HDFS: Number of bytes written=13
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=2040792
		Reduce input records=99129
		Reduce output records=2
		Spilled Records=99129
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=276824064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=13
2020-09-02 19:49:09,523 INFO mapred.LocalJobRunner: Finishing task: attempt_local1083685260_0001_r_000000_0
2020-09-02 19:49:09,523 INFO mapred.LocalJobRunner: reduce task executor complete.
2020-09-02 19:49:10,312 INFO mapreduce.Job:  map 100% reduce 100%
2020-09-02 19:49:10,314 INFO mapreduce.Job: Job job_local1083685260_0001 completed successfully
2020-09-02 19:49:10,329 INFO mapreduce.Job: Counters: 36
	File System Counters
		FILE: Number of bytes read=4435126
		FILE: Number of bytes written=7539498
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=293585392
		HDFS: Number of bytes written=13
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=268127
		Map output records=99129
		Map output bytes=1842528
		Map output materialized bytes=2040792
		Input split bytes=101
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=2040792
		Reduce input records=99129
		Reduce output records=2
		Spilled Records=198258
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=553648128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146792696
	File Output Format Counters 
		Bytes Written=13
2020-09-02 19:49:10,329 INFO streaming.StreamJob: Output directory: /Output/task1_aircraft





















































himanshu@himanshu:~/BigData/hadoop-3.2.1$ bin/hadoop jar '/home/himanshu/BigData/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar' -mapper "python /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/mapper_task1.py '@irplane'" -reducer 'python /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/reducer_task1.py' -input /Input/ -output /Output/task1_invalid
2020-09-02 19:50:37,000 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-09-02 19:50:37,258 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-09-02 19:50:37,258 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2020-09-02 19:50:37,326 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2020-09-02 19:50:37,918 INFO mapred.FileInputFormat: Total input files to process : 1
2020-09-02 19:50:37,944 INFO net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:9866
2020-09-02 19:50:38,002 INFO mapreduce.JobSubmitter: number of splits:1
2020-09-02 19:50:38,556 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1284520255_0001
2020-09-02 19:50:38,556 INFO mapreduce.JobSubmitter: Executing with tokens: []
2020-09-02 19:50:38,768 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2020-09-02 19:50:38,770 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2020-09-02 19:50:38,770 INFO mapreduce.Job: Running job: job_local1284520255_0001
2020-09-02 19:50:38,772 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2020-09-02 19:50:38,780 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:50:38,780 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:50:38,848 INFO mapred.LocalJobRunner: Waiting for map tasks
2020-09-02 19:50:38,853 INFO mapred.LocalJobRunner: Starting task: attempt_local1284520255_0001_m_000000_0
2020-09-02 19:50:38,896 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:50:38,896 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:50:38,932 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2020-09-02 19:50:38,947 INFO mapred.MapTask: Processing split: hdfs://localhost:8020/Input/plane_carriers.ndjson:0+146792696
2020-09-02 19:50:39,000 INFO mapred.MapTask: numReduceTasks: 1
2020-09-02 19:50:39,083 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2020-09-02 19:50:39,084 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2020-09-02 19:50:39,084 INFO mapred.MapTask: soft limit at 83886080
2020-09-02 19:50:39,084 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2020-09-02 19:50:39,084 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2020-09-02 19:50:39,087 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-09-02 19:50:39,092 INFO streaming.PipeMapRed: PipeMapRed exec [/home/himanshu/anaconda3/bin/python, /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/mapper_task1.py, @irplane]
2020-09-02 19:50:39,098 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2020-09-02 19:50:39,099 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
2020-09-02 19:50:39,099 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2020-09-02 19:50:39,100 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2020-09-02 19:50:39,101 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2020-09-02 19:50:39,101 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2020-09-02 19:50:39,102 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2020-09-02 19:50:39,103 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2020-09-02 19:50:39,104 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
2020-09-02 19:50:39,105 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2020-09-02 19:50:39,106 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2020-09-02 19:50:39,106 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2020-09-02 19:50:39,144 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-09-02 19:50:39,226 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:50:39,227 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:50:39,232 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:50:39,752 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:50:39,780 INFO mapreduce.Job: Job job_local1284520255_0001 running in uber mode : false
2020-09-02 19:50:39,782 INFO mapreduce.Job:  map 0% reduce 0%
2020-09-02 19:50:39,974 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:50:41,370 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:50000=100000/2 [rec/s] out:0=0/2 [rec/s]
2020-09-02 19:50:42,992 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:66666=200000/3 [rec/s] out:0=0/3 [rec/s]
2020-09-02 19:50:44,168 INFO streaming.PipeMapRed: Records R/W=268127/1
2020-09-02 19:50:44,171 INFO streaming.PipeMapRed: MRErrorThread done
2020-09-02 19:50:44,171 INFO streaming.PipeMapRed: mapRedFinished
2020-09-02 19:50:44,173 INFO mapred.LocalJobRunner: 
2020-09-02 19:50:44,173 INFO mapred.MapTask: Starting flush of map output
2020-09-02 19:50:44,173 INFO mapred.MapTask: Spilling map output
2020-09-02 19:50:44,174 INFO mapred.MapTask: bufstart = 0; bufend = 21; bufvoid = 104857600
2020-09-02 19:50:44,174 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2020-09-02 19:50:44,179 INFO mapred.MapTask: Finished spill 0
2020-09-02 19:50:44,197 INFO mapred.Task: Task:attempt_local1284520255_0001_m_000000_0 is done. And is in the process of committing
2020-09-02 19:50:44,203 INFO mapred.LocalJobRunner: Records R/W=268127/1
2020-09-02 19:50:44,204 INFO mapred.Task: Task 'attempt_local1284520255_0001_m_000000_0' done.
2020-09-02 19:50:44,213 INFO mapred.Task: Final Counters for attempt_local1284520255_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=176755
		FILE: Number of bytes written=708578
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=146792696
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=268127
		Map output records=2
		Map output bytes=21
		Map output materialized bytes=31
		Input split bytes=101
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=274726912
	File Input Format Counters 
		Bytes Read=146792696
2020-09-02 19:50:44,213 INFO mapred.LocalJobRunner: Finishing task: attempt_local1284520255_0001_m_000000_0
2020-09-02 19:50:44,214 INFO mapred.LocalJobRunner: map task executor complete.
2020-09-02 19:50:44,217 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2020-09-02 19:50:44,217 INFO mapred.LocalJobRunner: Starting task: attempt_local1284520255_0001_r_000000_0
2020-09-02 19:50:44,226 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2020-09-02 19:50:44,226 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-09-02 19:50:44,227 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2020-09-02 19:50:44,238 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30fb2aba
2020-09-02 19:50:44,242 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2020-09-02 19:50:44,274 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=629040704, maxSingleShuffleLimit=157260176, mergeThreshold=415166880, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-09-02 19:50:44,276 INFO reduce.EventFetcher: attempt_local1284520255_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-09-02 19:50:44,315 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1284520255_0001_m_000000_0 decomp: 27 len: 31 to MEMORY
2020-09-02 19:50:44,318 INFO reduce.InMemoryMapOutput: Read 27 bytes from map-output for attempt_local1284520255_0001_m_000000_0
2020-09-02 19:50:44,320 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 27, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->27
2020-09-02 19:50:44,321 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2020-09-02 19:50:44,338 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:50:44,338 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-09-02 19:50:44,348 INFO mapred.Merger: Merging 1 sorted segments
2020-09-02 19:50:44,348 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 16 bytes
2020-09-02 19:50:44,350 INFO reduce.MergeManagerImpl: Merged 1 segments, 27 bytes to disk to satisfy reduce memory limit
2020-09-02 19:50:44,350 INFO reduce.MergeManagerImpl: Merging 1 files, 31 bytes from disk
2020-09-02 19:50:44,351 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2020-09-02 19:50:44,352 INFO mapred.Merger: Merging 1 sorted segments
2020-09-02 19:50:44,353 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 16 bytes
2020-09-02 19:50:44,353 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:50:44,364 INFO streaming.PipeMapRed: PipeMapRed exec [/home/himanshu/anaconda3/bin/python, /home/himanshu/Github/Big_Data_UE18CS322/Assignment1/Task1/reducer_task1.py]
2020-09-02 19:50:44,367 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2020-09-02 19:50:44,368 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2020-09-02 19:50:44,435 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2020-09-02 19:50:44,438 INFO streaming.PipeMapRed: MRErrorThread done
2020-09-02 19:50:44,439 INFO streaming.PipeMapRed: mapRedFinished
2020-09-02 19:50:44,458 INFO mapred.Task: Task:attempt_local1284520255_0001_r_000000_0 is done. And is in the process of committing
2020-09-02 19:50:44,460 INFO mapred.LocalJobRunner: 1 / 1 copied.
2020-09-02 19:50:44,460 INFO mapred.Task: Task attempt_local1284520255_0001_r_000000_0 is allowed to commit now
2020-09-02 19:50:44,500 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1284520255_0001_r_000000_0' to hdfs://localhost:8020/Output/task1_invalid
2020-09-02 19:50:44,500 INFO mapred.LocalJobRunner: reduce > reduce
2020-09-02 19:50:44,501 INFO mapred.Task: Task 'attempt_local1284520255_0001_r_000000_0' done.
2020-09-02 19:50:44,501 INFO mapred.Task: Final Counters for attempt_local1284520255_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=176849
		FILE: Number of bytes written=708609
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=146792696
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=31
		Reduce input records=2
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=276299776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2020-09-02 19:50:44,501 INFO mapred.LocalJobRunner: Finishing task: attempt_local1284520255_0001_r_000000_0
2020-09-02 19:50:44,502 INFO mapred.LocalJobRunner: reduce task executor complete.
2020-09-02 19:50:44,787 INFO mapreduce.Job:  map 100% reduce 100%
2020-09-02 19:50:44,788 INFO mapreduce.Job: Job job_local1284520255_0001 completed successfully
2020-09-02 19:50:44,817 INFO mapreduce.Job: Counters: 36
	File System Counters
		FILE: Number of bytes read=353604
		FILE: Number of bytes written=1417187
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=293585392
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=268127
		Map output records=2
		Map output bytes=21
		Map output materialized bytes=31
		Input split bytes=101
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=31
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=551026688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146792696
	File Output Format Counters 
		Bytes Written=0
2020-09-02 19:50:44,817 INFO streaming.StreamJob: Output directory: /Output/task1_invalid
